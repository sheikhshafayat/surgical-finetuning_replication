{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from robustness import datasets\n",
    "from robustness.tools.breeds_helpers import make_living17\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import sampler\n",
    "import os\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from trainer_functions.customImageNettrainer import build_resnet50, evaluate_customImageNet, train_customImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/rada/.mxnet/datasets/imagenet'\n",
    "info_dir = '/Users/rada/Documents/GitHub/BREEDS-Benchmarks/imagenet_class_hierarchy/modified'\n",
    "\n",
    "n_subset = 850\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # empty dataframe\n",
    "# df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "# ret = make_living17(info_dir, split=\"rand\")\n",
    "# superclasses, subclass_split, label_map = ret\n",
    "# train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "# dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "# loaders_source = dataset_source.make_loaders(\n",
    "#     workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "# train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "# dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "# loaders_target = dataset_target.make_loaders(\n",
    "#     workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "# train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "# device = torch.device(\"mps\")\n",
    "# tune_net = build_resnet50(device)\n",
    "\n",
    "# optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.0001)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_source,\n",
    "#                            val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "# optimizer = optim.Adam(tune_net.parameters(), lr=0.0001)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_source,\n",
    "#                            val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# # first layer is fine-tuned\n",
    "# optimizer = optim.Adam(tune_net.layer1.parameters(), lr=lr)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_target,\n",
    "#                            val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# # adding results to dataframe\n",
    "# dict = {}\n",
    "# dict['accuracy'] = acc\n",
    "# dict['lr'] = lr\n",
    "# dict['state'] = \"first layer\"  # change when run\n",
    "# dict['n_subset'] = n_subset\n",
    "# df_temp = pd.DataFrame(dict, index=[0])\n",
    "# df = pd.concat([df, df_temp])\n",
    "\n",
    "# # change when run\n",
    "# df.to_csv(\"Living17_layer1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # empty dataframe\n",
    "# df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "# ret = make_living17(info_dir, split=\"rand\")\n",
    "# superclasses, subclass_split, label_map = ret\n",
    "# train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "# dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "# loaders_source = dataset_source.make_loaders(\n",
    "#     workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "# train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "# dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "# loaders_target = dataset_target.make_loaders(\n",
    "#     workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "# train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "# device = torch.device(\"mps\")\n",
    "# tune_net = build_resnet50(device)\n",
    "\n",
    "# optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_source,\n",
    "#                            val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "# optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_source,\n",
    "#                            val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# # second layer is fine-tuned\n",
    "# optimizer = optim.Adam(tune_net.layer2.parameters(), lr=lr)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_target,\n",
    "#                            val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# # adding results to dataframe\n",
    "# dict = {}\n",
    "# dict['accuracy'] = acc\n",
    "# dict['lr'] = lr\n",
    "# dict['state'] = \"second layer\"  # change when run\n",
    "# dict['n_subset'] = n_subset\n",
    "# df_temp = pd.DataFrame(dict, index=[0])\n",
    "# df = pd.concat([df, df_temp])\n",
    "\n",
    "# # change when run\n",
    "# df.to_csv(\"Living17_layer2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # empty dataframe\n",
    "# df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "# ret = make_living17(info_dir, split=\"rand\")\n",
    "# superclasses, subclass_split, label_map = ret\n",
    "# train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "# dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "# loaders_source = dataset_source.make_loaders(\n",
    "#     workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "# train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "# dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "# loaders_target = dataset_target.make_loaders(\n",
    "#     workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "# train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "# device = torch.device(\"mps\")\n",
    "# tune_net = build_resnet50(device)\n",
    "\n",
    "# optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_source,\n",
    "#                            val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "# optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_source,\n",
    "#                            val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# # third layer is fine-tuned\n",
    "# optimizer = optim.Adam(tune_net.layer3.parameters(), lr=lr)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# acc = train_customImageNet(tune_net, train_loader_target,\n",
    "#                            val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# # adding results to dataframe\n",
    "# dict = {}\n",
    "# dict['accuracy'] = acc\n",
    "# dict['lr'] = lr\n",
    "# dict['state'] = \"third layer\"  # change when run\n",
    "# dict['n_subset'] = n_subset\n",
    "# df_temp = pd.DataFrame(dict, index=[0])\n",
    "# df = pd.concat([df, df_temp])\n",
    "\n",
    "# # change when run\n",
    "# df.to_csv(\"Living17_layer3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.0026, lr 0.00100000\n",
      "Got 8 / 1700 correct (0.47)\n",
      "\n",
      "Epoch 1, loss = 3.4673, lr 0.00100000\n",
      "Got 107 / 1700 correct (6.29)\n",
      "\n",
      "Epoch 2, loss = 2.1360, lr 0.00100000\n",
      "Got 322 / 1700 correct (18.94)\n",
      "\n",
      "Epoch 0, loss = 1.2435, lr 0.00100000\n",
      "Got 1050 / 1700 correct (61.76)\n",
      "\n",
      "Epoch 1, loss = 1.7257, lr 0.00100000\n",
      "Got 829 / 1700 correct (48.76)\n",
      "\n",
      "Epoch 0, loss = 1.6443, lr 0.00050000\n",
      "Got 1298 / 1700 correct (76.35)\n",
      "\n",
      "Epoch 1, loss = 0.8234, lr 0.00050000\n",
      "Got 1388 / 1700 correct (81.65)\n",
      "\n",
      "Epoch 2, loss = 0.7612, lr 0.00050000\n",
      "Got 1441 / 1700 correct (84.76)\n",
      "\n",
      "Epoch 3, loss = 0.9583, lr 0.00050000\n",
      "Got 1453 / 1700 correct (85.47)\n",
      "\n",
      "Epoch 4, loss = 0.7202, lr 0.00050000\n",
      "Got 1472 / 1700 correct (86.59)\n",
      "\n",
      "Epoch 5, loss = 0.9824, lr 0.00050000\n",
      "Got 1451 / 1700 correct (85.35)\n",
      "\n",
      "Epoch 6, loss = 0.6782, lr 0.00050000\n",
      "Got 1428 / 1700 correct (84.00)\n",
      "\n",
      "Epoch 7, loss = 0.4789, lr 0.00050000\n",
      "Got 1432 / 1700 correct (84.24)\n",
      "\n",
      "Epoch 8, loss = 0.1133, lr 0.00050000\n",
      "Got 1448 / 1700 correct (85.18)\n",
      "\n",
      "Epoch 9, loss = 0.3258, lr 0.00050000\n",
      "Got 1435 / 1700 correct (84.41)\n",
      "\n",
      "Epoch 10, loss = 0.6006, lr 0.00050000\n",
      "Got 1408 / 1700 correct (82.82)\n",
      "\n",
      "Epoch 11, loss = 0.3436, lr 0.00050000\n",
      "Got 1438 / 1700 correct (84.59)\n",
      "\n",
      "Epoch 12, loss = 0.2823, lr 0.00050000\n",
      "Got 1431 / 1700 correct (84.18)\n",
      "\n",
      "Epoch 13, loss = 0.0602, lr 0.00050000\n",
      "Got 1410 / 1700 correct (82.94)\n",
      "\n",
      "Epoch 14, loss = 0.2321, lr 0.00050000\n",
      "Got 1419 / 1700 correct (83.47)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# fourth layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.layer4.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "model_scripted = torch.jit.script(tune_net) # Export to TorchScript\n",
    "model_scripted.save('Living17_layer4.pt')\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"fourth layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_layer4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.6490, lr 0.00100000\n",
      "Got 12 / 1700 correct (0.71)\n",
      "\n",
      "Epoch 1, loss = 2.7915, lr 0.00100000\n",
      "Got 119 / 1700 correct (7.00)\n",
      "\n",
      "Epoch 2, loss = 2.1230, lr 0.00100000\n",
      "Got 342 / 1700 correct (20.12)\n",
      "\n",
      "Epoch 0, loss = 1.4775, lr 0.00100000\n",
      "Got 917 / 1700 correct (53.94)\n",
      "\n",
      "Epoch 1, loss = 1.1029, lr 0.00100000\n",
      "Got 1026 / 1700 correct (60.35)\n",
      "\n",
      "Epoch 0, loss = 1.7605, lr 0.00050000\n",
      "Got 844 / 1700 correct (49.65)\n",
      "\n",
      "Epoch 1, loss = 1.7414, lr 0.00050000\n",
      "Got 956 / 1700 correct (56.24)\n",
      "\n",
      "Epoch 2, loss = 1.0393, lr 0.00050000\n",
      "Got 1015 / 1700 correct (59.71)\n",
      "\n",
      "Epoch 3, loss = 1.2133, lr 0.00050000\n",
      "Got 1076 / 1700 correct (63.29)\n",
      "\n",
      "Epoch 4, loss = 1.0785, lr 0.00050000\n",
      "Got 1129 / 1700 correct (66.41)\n",
      "\n",
      "Epoch 5, loss = 1.2221, lr 0.00050000\n",
      "Got 1167 / 1700 correct (68.65)\n",
      "\n",
      "Epoch 6, loss = 1.3527, lr 0.00050000\n",
      "Got 1210 / 1700 correct (71.18)\n",
      "\n",
      "Epoch 7, loss = 1.1120, lr 0.00050000\n",
      "Got 1228 / 1700 correct (72.24)\n",
      "\n",
      "Epoch 8, loss = 1.2045, lr 0.00050000\n",
      "Got 1262 / 1700 correct (74.24)\n",
      "\n",
      "Epoch 9, loss = 1.1024, lr 0.00050000\n",
      "Got 1262 / 1700 correct (74.24)\n",
      "\n",
      "Epoch 10, loss = 1.4714, lr 0.00050000\n",
      "Got 1285 / 1700 correct (75.59)\n",
      "\n",
      "Epoch 11, loss = 0.6051, lr 0.00050000\n",
      "Got 1276 / 1700 correct (75.06)\n",
      "\n",
      "Epoch 12, loss = 0.6507, lr 0.00050000\n",
      "Got 1287 / 1700 correct (75.71)\n",
      "\n",
      "Epoch 13, loss = 0.9572, lr 0.00050000\n",
      "Got 1303 / 1700 correct (76.65)\n",
      "\n",
      "Epoch 14, loss = 1.0760, lr 0.00050000\n",
      "Got 1322 / 1700 correct (77.76)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# last layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "model_scripted = torch.jit.script(tune_net) # Export to TorchScript\n",
    "model_scripted.save('Living17_last_layer.pt')\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"last layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_last_layer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.9058, lr 0.00100000\n",
      "Got 11 / 1700 correct (0.65)\n",
      "\n",
      "Epoch 1, loss = 3.0341, lr 0.00100000\n",
      "Got 113 / 1700 correct (6.65)\n",
      "\n",
      "Epoch 2, loss = 2.5737, lr 0.00100000\n",
      "Got 290 / 1700 correct (17.06)\n",
      "\n",
      "Epoch 0, loss = 0.6148, lr 0.00100000\n",
      "Got 943 / 1700 correct (55.47)\n",
      "\n",
      "Epoch 1, loss = 1.2378, lr 0.00100000\n",
      "Got 910 / 1700 correct (53.53)\n",
      "\n",
      "Epoch 0, loss = 1.3533, lr 0.00050000\n",
      "Got 1100 / 1700 correct (64.71)\n",
      "\n",
      "Epoch 1, loss = 0.4466, lr 0.00050000\n",
      "Got 1325 / 1700 correct (77.94)\n",
      "\n",
      "Epoch 2, loss = 1.5443, lr 0.00050000\n",
      "Got 1414 / 1700 correct (83.18)\n",
      "\n",
      "Epoch 3, loss = 0.2726, lr 0.00050000\n",
      "Got 1368 / 1700 correct (80.47)\n",
      "\n",
      "Epoch 4, loss = 0.9261, lr 0.00050000\n",
      "Got 1344 / 1700 correct (79.06)\n",
      "\n",
      "Epoch 5, loss = 0.5626, lr 0.00050000\n",
      "Got 1319 / 1700 correct (77.59)\n",
      "\n",
      "Epoch 6, loss = 0.7907, lr 0.00050000\n",
      "Got 1359 / 1700 correct (79.94)\n",
      "\n",
      "Epoch 7, loss = 0.6840, lr 0.00050000\n",
      "Got 1393 / 1700 correct (81.94)\n",
      "\n",
      "Epoch 8, loss = 0.5603, lr 0.00050000\n",
      "Got 1351 / 1700 correct (79.47)\n",
      "\n",
      "Epoch 9, loss = 0.3413, lr 0.00050000\n",
      "Got 1415 / 1700 correct (83.24)\n",
      "\n",
      "Epoch 10, loss = 0.1451, lr 0.00050000\n",
      "Got 1396 / 1700 correct (82.12)\n",
      "\n",
      "Epoch 11, loss = 0.2263, lr 0.00050000\n",
      "Got 1401 / 1700 correct (82.41)\n",
      "\n",
      "Epoch 12, loss = 0.1141, lr 0.00050000\n",
      "Got 1402 / 1700 correct (82.47)\n",
      "\n",
      "Epoch 13, loss = 0.1303, lr 0.00050000\n",
      "Got 1397 / 1700 correct (82.18)\n",
      "\n",
      "Epoch 14, loss = 0.5355, lr 0.00050000\n",
      "Got 1422 / 1700 correct (83.65)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# all layers is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "model_scripted = torch.jit.script(tune_net) # Export to TorchScript\n",
    "model_scripted.save('Living17_all_layers.pt')\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"all layers\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_alllayers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pytorch_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be375b19548401d9264c26e1cb16ccfdbed2c1020c05f692b19335077b4aa958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
