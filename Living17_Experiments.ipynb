{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transforms' from 'torchvision' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrobustness\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrobustness\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbreeds_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_living17\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_m1/lib/python3.8/site-packages/robustness/datasets.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m imagenet_models, cifar_models\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms, datasets\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m constants\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m openimgs_helpers\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'transforms' from 'torchvision' (unknown location)"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from robustness import datasets\n",
    "from robustness.tools.breeds_helpers import make_living17\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import sampler\n",
    "import os\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from trainer_functions.living17trainer import build_resnet50, evaluate_living17, train_living17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "data_dir = '/Users/rada/.mxnet/datasets/imagenet'\n",
    "info_dir = '/Users/rada/Documents/GitHub/BREEDS-Benchmarks/imagenet_class_hierarchy/modified'\n",
    "\n",
    "n_subset = 850\n",
    "lrs = [0.0005, 1e-4, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu device type at start of device string: mps",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m loaders_target \u001b[38;5;241m=\u001b[39m dataset_target\u001b[38;5;241m.\u001b[39mmake_loaders(workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shuffle_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m850\u001b[39m)\n\u001b[1;32m     13\u001b[0m train_loader_target, val_loader_target \u001b[38;5;241m=\u001b[39m loaders_target\n\u001b[0;32m---> 15\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m tune_net \u001b[38;5;241m=\u001b[39m build_resnet50(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# tune_net.layer1 to tune the first layer, tune_net to tune all layers, tune_net.fc to tune the last year\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# add linear probing here\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu device type at start of device string: mps"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    \n",
    "    ret = make_living17(info_dir, split=\"rand\")\n",
    "    superclasses, subclass_split, label_map = ret\n",
    "    train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "    dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "    loaders_source = dataset_source.make_loaders(workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "    train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "    dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "    loaders_target = dataset_target.make_loaders(workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "    train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "    device = torch.device(\"mps\")\n",
    "    tune_net = build_resnet50(device)\n",
    "\n",
    "    # tune_net.layer1 to tune the first layer, tune_net to tune all layers, tune_net.fc to tune the last year\n",
    "    # add linear probing here\n",
    "    optimizer = optim.Adam(tune_net.fc.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    acc = train_living17(tune_net, train_loader_source, val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "    \n",
    "    optimizer = optim.Adam(tune_net.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    acc = train_living17(tune_net, train_loader_source, val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "    optimizer = optim.Adam(tune_net.layer1.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    acc = train_living17(tune_net, train_loader_target, val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "    \n",
    "    # adding results to dataframe\n",
    "    dict = {}\n",
    "    dict['accuracy'] = acc\n",
    "    dict['lr'] = lr\n",
    "    dict['state'] = \"first layer\"  # change when run\n",
    "    dict['n_subset'] = n_subset\n",
    "    df_temp = pd.DataFrame(dict, index=[0])\n",
    "    df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_layer1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pytorch_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be375b19548401d9264c26e1cb16ccfdbed2c1020c05f692b19335077b4aa958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
