{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from robustness import datasets\n",
    "from robustness.tools.breeds_helpers import make_living17\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import sampler\n",
    "import os\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "# for plotting\n",
    "\n",
    "from trainer_functions.customImageNettrainer import build_resnet50, evaluate_customImageNet, train_customImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/rada/.mxnet/datasets/imagenet'\n",
    "info_dir = '/Users/rada/Documents/GitHub/BREEDS-Benchmarks/imagenet_class_hierarchy/modified'\n",
    "\n",
    "n_subset = 850\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # empty dataframe\\ndf = pd.DataFrame(columns=[\\'accuracy\\', \"lr\", \"state\", \"n_subset\"])\\n\\nret = make_living17(info_dir, split=\"rand\")\\nsuperclasses, subclass_split, label_map = ret\\ntrain_subclasses, test_subclasses = subclass_split\\n\\ndataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\\nloaders_source = dataset_source.make_loaders(\\n    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\\ntrain_loader_source, val_loader_source = loaders_source\\n\\ndataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\\nloaders_target = dataset_target.make_loaders(\\n    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\\ntrain_loader_target, val_loader_target = loaders_target\\n\\ndevice = torch.device(\"mps\")\\ntune_net = build_resnet50(device)\\n\\noptimizer = optim.Adam(tune_net.fc.parameters(), lr=0.0001)\\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\\nacc = train_customImageNet(tune_net, train_loader_source,\\n                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\\n\\noptimizer = optim.Adam(tune_net.parameters(), lr=0.0001)\\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\\nacc = train_customImageNet(tune_net, train_loader_source,\\n                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\\n\\n# first layer is fine-tuned\\noptimizer = optim.Adam(tune_net.layer1.parameters(), lr=lr)\\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\\nacc = train_customImageNet(tune_net, train_loader_target,\\n                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\\n\\n# adding results to dataframe\\ndict = {}\\ndict[\\'accuracy\\'] = acc\\ndict[\\'lr\\'] = lr\\ndict[\\'state\\'] = \"first layer\"  # change when run\\ndict[\\'n_subset\\'] = n_subset\\ndf_temp = pd.DataFrame(dict, index=[0])\\ndf = pd.concat([df, df_temp])\\n\\n# change when run\\ndf.to_csv(\"Living17_layer1.csv\") '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# first layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.layer1.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"first layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_layer1.csv\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.1121, lr 0.00100000\n",
      "Got 9 / 1700 correct (0.53)\n",
      "\n",
      "Epoch 1, loss = 3.1633, lr 0.00100000\n",
      "Got 116 / 1700 correct (6.82)\n",
      "\n",
      "Epoch 2, loss = 2.3018, lr 0.00100000\n",
      "Got 325 / 1700 correct (19.12)\n",
      "\n",
      "Epoch 0, loss = 1.1397, lr 0.00100000\n",
      "Got 1147 / 1700 correct (67.47)\n",
      "\n",
      "Epoch 1, loss = 0.8010, lr 0.00100000\n",
      "Got 1018 / 1700 correct (59.88)\n",
      "\n",
      "Epoch 0, loss = 2.4053, lr 0.00050000\n",
      "Got 829 / 1700 correct (48.76)\n",
      "\n",
      "Epoch 1, loss = 2.7847, lr 0.00050000\n",
      "Got 907 / 1700 correct (53.35)\n",
      "\n",
      "Epoch 2, loss = 1.7788, lr 0.00050000\n",
      "Got 969 / 1700 correct (57.00)\n",
      "\n",
      "Epoch 3, loss = 1.9061, lr 0.00050000\n",
      "Got 1003 / 1700 correct (59.00)\n",
      "\n",
      "Epoch 4, loss = 1.8682, lr 0.00050000\n",
      "Got 1028 / 1700 correct (60.47)\n",
      "\n",
      "Epoch 5, loss = 1.0223, lr 0.00050000\n",
      "Got 1046 / 1700 correct (61.53)\n",
      "\n",
      "Epoch 6, loss = 0.7554, lr 0.00050000\n",
      "Got 1082 / 1700 correct (63.65)\n",
      "\n",
      "Epoch 7, loss = 1.3301, lr 0.00050000\n",
      "Got 1104 / 1700 correct (64.94)\n",
      "\n",
      "Epoch 8, loss = 1.1052, lr 0.00050000\n",
      "Got 1105 / 1700 correct (65.00)\n",
      "\n",
      "Epoch 9, loss = 1.7692, lr 0.00050000\n",
      "Got 1113 / 1700 correct (65.47)\n",
      "\n",
      "Epoch 10, loss = 1.3473, lr 0.00050000\n",
      "Got 1140 / 1700 correct (67.06)\n",
      "\n",
      "Epoch 11, loss = 0.9963, lr 0.00050000\n",
      "Got 1160 / 1700 correct (68.24)\n",
      "\n",
      "Epoch 12, loss = 1.3704, lr 0.00050000\n",
      "Got 1163 / 1700 correct (68.41)\n",
      "\n",
      "Epoch 13, loss = 1.2917, lr 0.00050000\n",
      "Got 1131 / 1700 correct (66.53)\n",
      "\n",
      "Epoch 14, loss = 1.1816, lr 0.00050000\n",
      "Got 1173 / 1700 correct (69.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# second layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.layer2.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"second layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_layer2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 5.1348, lr 0.00100000\n",
      "Got 9 / 1700 correct (0.53)\n",
      "\n",
      "Epoch 1, loss = 3.0784, lr 0.00100000\n",
      "Got 104 / 1700 correct (6.12)\n",
      "\n",
      "Epoch 2, loss = 2.5171, lr 0.00100000\n",
      "Got 313 / 1700 correct (18.41)\n",
      "\n",
      "Epoch 0, loss = 0.8862, lr 0.00100000\n",
      "Got 736 / 1700 correct (43.29)\n",
      "\n",
      "Epoch 1, loss = 1.1265, lr 0.00100000\n",
      "Got 890 / 1700 correct (52.35)\n",
      "\n",
      "Epoch 0, loss = 1.8971, lr 0.00050000\n",
      "Got 1089 / 1700 correct (64.06)\n",
      "\n",
      "Epoch 1, loss = 1.4336, lr 0.00050000\n",
      "Got 1220 / 1700 correct (71.76)\n",
      "\n",
      "Epoch 2, loss = 0.5061, lr 0.00050000\n",
      "Got 1293 / 1700 correct (76.06)\n",
      "\n",
      "Epoch 3, loss = 0.9557, lr 0.00050000\n",
      "Got 1335 / 1700 correct (78.53)\n",
      "\n",
      "Epoch 4, loss = 0.8969, lr 0.00050000\n",
      "Got 1357 / 1700 correct (79.82)\n",
      "\n",
      "Epoch 5, loss = 0.6619, lr 0.00050000\n",
      "Got 1370 / 1700 correct (80.59)\n",
      "\n",
      "Epoch 6, loss = 0.3786, lr 0.00050000\n",
      "Got 1352 / 1700 correct (79.53)\n",
      "\n",
      "Epoch 7, loss = 0.1445, lr 0.00050000\n",
      "Got 1340 / 1700 correct (78.82)\n",
      "\n",
      "Epoch 8, loss = 0.6256, lr 0.00050000\n",
      "Got 1368 / 1700 correct (80.47)\n",
      "\n",
      "Epoch 9, loss = 0.4261, lr 0.00050000\n",
      "Got 1391 / 1700 correct (81.82)\n",
      "\n",
      "Epoch 10, loss = 0.5924, lr 0.00050000\n",
      "Got 1388 / 1700 correct (81.65)\n",
      "\n",
      "Epoch 11, loss = 0.2074, lr 0.00050000\n",
      "Got 1364 / 1700 correct (80.24)\n",
      "\n",
      "Epoch 12, loss = 0.3194, lr 0.00050000\n",
      "Got 1397 / 1700 correct (82.18)\n",
      "\n",
      "Epoch 13, loss = 0.4441, lr 0.00050000\n",
      "Got 1403 / 1700 correct (82.53)\n",
      "\n",
      "Epoch 14, loss = 0.4661, lr 0.00050000\n",
      "Got 1367 / 1700 correct (80.41)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# third layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.layer3.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"third layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_layer3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.4758, lr 0.00100000\n",
      "Got 8 / 1700 correct (0.47)\n",
      "\n",
      "Epoch 1, loss = 3.4250, lr 0.00100000\n",
      "Got 122 / 1700 correct (7.18)\n",
      "\n",
      "Epoch 2, loss = 2.4645, lr 0.00100000\n",
      "Got 312 / 1700 correct (18.35)\n",
      "\n",
      "Epoch 0, loss = 1.5637, lr 0.00100000\n",
      "Got 972 / 1700 correct (57.18)\n",
      "\n",
      "Epoch 1, loss = 0.3767, lr 0.00100000\n",
      "Got 1013 / 1700 correct (59.59)\n",
      "\n",
      "Epoch 0, loss = 1.3796, lr 0.00050000\n",
      "Got 1288 / 1700 correct (75.76)\n",
      "\n",
      "Epoch 1, loss = 0.8569, lr 0.00050000\n",
      "Got 1364 / 1700 correct (80.24)\n",
      "\n",
      "Epoch 2, loss = 0.9448, lr 0.00050000\n",
      "Got 1420 / 1700 correct (83.53)\n",
      "\n",
      "Epoch 3, loss = 0.3999, lr 0.00050000\n",
      "Got 1451 / 1700 correct (85.35)\n",
      "\n",
      "Epoch 4, loss = 1.1652, lr 0.00050000\n",
      "Got 1431 / 1700 correct (84.18)\n",
      "\n",
      "Epoch 5, loss = 0.8514, lr 0.00050000\n",
      "Got 1436 / 1700 correct (84.47)\n",
      "\n",
      "Epoch 6, loss = 0.2608, lr 0.00050000\n",
      "Got 1461 / 1700 correct (85.94)\n",
      "\n",
      "Epoch 7, loss = 0.3002, lr 0.00050000\n",
      "Got 1444 / 1700 correct (84.94)\n",
      "\n",
      "Epoch 8, loss = 0.5012, lr 0.00050000\n",
      "Got 1466 / 1700 correct (86.24)\n",
      "\n",
      "Epoch 9, loss = 0.4894, lr 0.00050000\n",
      "Got 1446 / 1700 correct (85.06)\n",
      "\n",
      "Epoch 10, loss = 0.4220, lr 0.00050000\n",
      "Got 1422 / 1700 correct (83.65)\n",
      "\n",
      "Epoch 11, loss = 0.3121, lr 0.00050000\n",
      "Got 1459 / 1700 correct (85.82)\n",
      "\n",
      "Epoch 12, loss = 0.7085, lr 0.00050000\n",
      "Got 1454 / 1700 correct (85.53)\n",
      "\n",
      "Epoch 13, loss = 0.5494, lr 0.00050000\n",
      "Got 1440 / 1700 correct (84.71)\n",
      "\n",
      "Epoch 14, loss = 0.1377, lr 0.00050000\n",
      "Got 1433 / 1700 correct (84.29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# fourth layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.layer4.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"fourth layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_layer4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.5696, lr 0.00100000\n",
      "Got 8 / 1700 correct (0.47)\n",
      "\n",
      "Epoch 1, loss = 3.2621, lr 0.00100000\n",
      "Got 110 / 1700 correct (6.47)\n",
      "\n",
      "Epoch 2, loss = 2.3200, lr 0.00100000\n",
      "Got 325 / 1700 correct (19.12)\n",
      "\n",
      "Epoch 0, loss = 1.6083, lr 0.00100000\n",
      "Got 927 / 1700 correct (54.53)\n",
      "\n",
      "Epoch 1, loss = 0.8425, lr 0.00100000\n",
      "Got 1132 / 1700 correct (66.59)\n",
      "\n",
      "Epoch 0, loss = 1.5924, lr 0.00050000\n",
      "Got 867 / 1700 correct (51.00)\n",
      "\n",
      "Epoch 1, loss = 1.5459, lr 0.00050000\n",
      "Got 955 / 1700 correct (56.18)\n",
      "\n",
      "Epoch 2, loss = 1.5987, lr 0.00050000\n",
      "Got 1028 / 1700 correct (60.47)\n",
      "\n",
      "Epoch 3, loss = 0.9419, lr 0.00050000\n",
      "Got 1099 / 1700 correct (64.65)\n",
      "\n",
      "Epoch 4, loss = 1.1386, lr 0.00050000\n",
      "Got 1142 / 1700 correct (67.18)\n",
      "\n",
      "Epoch 5, loss = 1.0972, lr 0.00050000\n",
      "Got 1174 / 1700 correct (69.06)\n",
      "\n",
      "Epoch 6, loss = 1.8561, lr 0.00050000\n",
      "Got 1205 / 1700 correct (70.88)\n",
      "\n",
      "Epoch 7, loss = 0.8144, lr 0.00050000\n",
      "Got 1236 / 1700 correct (72.71)\n",
      "\n",
      "Epoch 8, loss = 1.4231, lr 0.00050000\n",
      "Got 1257 / 1700 correct (73.94)\n",
      "\n",
      "Epoch 9, loss = 1.6120, lr 0.00050000\n",
      "Got 1275 / 1700 correct (75.00)\n",
      "\n",
      "Epoch 10, loss = 1.1079, lr 0.00050000\n",
      "Got 1300 / 1700 correct (76.47)\n",
      "\n",
      "Epoch 11, loss = 0.6146, lr 0.00050000\n",
      "Got 1308 / 1700 correct (76.94)\n",
      "\n",
      "Epoch 12, loss = 0.9647, lr 0.00050000\n",
      "Got 1317 / 1700 correct (77.47)\n",
      "\n",
      "Epoch 13, loss = 0.8461, lr 0.00050000\n",
      "Got 1333 / 1700 correct (78.41)\n",
      "\n",
      "Epoch 14, loss = 0.9768, lr 0.00050000\n",
      "Got 1329 / 1700 correct (78.18)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# last layer is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"last layer\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_last_layer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset custom_imagenet..\n",
      "==> Preparing dataset custom_imagenet..\n",
      "Building model...\n",
      "Epoch 0, loss = 4.4790, lr 0.00100000\n",
      "Got 14 / 1700 correct (0.82)\n",
      "\n",
      "Epoch 1, loss = 2.7285, lr 0.00100000\n",
      "Got 134 / 1700 correct (7.88)\n",
      "\n",
      "Epoch 2, loss = 2.2932, lr 0.00100000\n",
      "Got 319 / 1700 correct (18.76)\n",
      "\n",
      "Epoch 0, loss = 1.2226, lr 0.00100000\n",
      "Got 869 / 1700 correct (51.12)\n",
      "\n",
      "Epoch 1, loss = 1.5237, lr 0.00100000\n",
      "Got 959 / 1700 correct (56.41)\n",
      "\n",
      "Epoch 0, loss = 1.5870, lr 0.00050000\n",
      "Got 1182 / 1700 correct (69.53)\n",
      "\n",
      "Epoch 1, loss = 0.6880, lr 0.00050000\n",
      "Got 1383 / 1700 correct (81.35)\n",
      "\n",
      "Epoch 2, loss = 0.8356, lr 0.00050000\n",
      "Got 1410 / 1700 correct (82.94)\n",
      "\n",
      "Epoch 3, loss = 0.7548, lr 0.00050000\n",
      "Got 1385 / 1700 correct (81.47)\n",
      "\n",
      "Epoch 4, loss = 0.1644, lr 0.00050000\n",
      "Got 1423 / 1700 correct (83.71)\n",
      "\n",
      "Epoch 5, loss = 0.3517, lr 0.00050000\n",
      "Got 1389 / 1700 correct (81.71)\n",
      "\n",
      "Epoch 6, loss = 0.7651, lr 0.00050000\n",
      "Got 1415 / 1700 correct (83.24)\n",
      "\n",
      "Epoch 7, loss = 0.4718, lr 0.00050000\n",
      "Got 1414 / 1700 correct (83.18)\n",
      "\n",
      "Epoch 8, loss = 0.4965, lr 0.00050000\n",
      "Got 1398 / 1700 correct (82.24)\n",
      "\n",
      "Epoch 9, loss = 0.2410, lr 0.00050000\n",
      "Got 1367 / 1700 correct (80.41)\n",
      "\n",
      "Epoch 10, loss = 0.4849, lr 0.00050000\n",
      "Got 1407 / 1700 correct (82.76)\n",
      "\n",
      "Epoch 11, loss = 0.3244, lr 0.00050000\n",
      "Got 1407 / 1700 correct (82.76)\n",
      "\n",
      "Epoch 12, loss = 0.0407, lr 0.00050000\n",
      "Got 1401 / 1700 correct (82.41)\n",
      "\n",
      "Epoch 13, loss = 0.3117, lr 0.00050000\n",
      "Got 1422 / 1700 correct (83.65)\n",
      "\n",
      "Epoch 14, loss = 0.5409, lr 0.00050000\n",
      "Got 1370 / 1700 correct (80.59)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['accuracy', \"lr\", \"state\", \"n_subset\"])\n",
    "\n",
    "ret = make_living17(info_dir, split=\"rand\")\n",
    "superclasses, subclass_split, label_map = ret\n",
    "train_subclasses, test_subclasses = subclass_split\n",
    "\n",
    "dataset_source = datasets.CustomImageNet(data_dir, train_subclasses)\n",
    "loaders_source = dataset_source.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=64, shuffle_val=64, subset=850)\n",
    "train_loader_source, val_loader_source = loaders_source\n",
    "\n",
    "dataset_target = datasets.CustomImageNet(data_dir, test_subclasses)\n",
    "loaders_target = dataset_target.make_loaders(\n",
    "    workers=10, batch_size=64, shuffle_train=True, shuffle_val=True, subset=850)\n",
    "train_loader_target, val_loader_target = loaders_target\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "tune_net = build_resnet50(device)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=3)\n",
    "\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_source,\n",
    "                           val_loader_source, optimizer, scheduler, device=device, epochs=2)\n",
    "\n",
    "# all layers is fine-tuned\n",
    "optimizer = optim.Adam(tune_net.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "acc = train_customImageNet(tune_net, train_loader_target,\n",
    "                           val_loader_target, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "# adding results to dataframe\n",
    "dict = {}\n",
    "dict['accuracy'] = acc\n",
    "dict['lr'] = lr\n",
    "dict['state'] = \"all layers\"  # change when run\n",
    "dict['n_subset'] = n_subset\n",
    "df_temp = pd.DataFrame(dict, index=[0])\n",
    "df = pd.concat([df, df_temp])\n",
    "\n",
    "# change when run\n",
    "df.to_csv(\"Living17_alllayers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pytorch_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be375b19548401d9264c26e1cb16ccfdbed2c1020c05f692b19335077b4aa958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
