{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import sampler\n",
    "import os\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from trainer_functions.cifartrainer import evaluate_cifar, train_cifar, build_cifar10, build_cifar10noise\n",
    "from models.ResNet import ResNetCifar as ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 45000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 48000)))\n",
    "loader_val_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(48000, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "device = torch.device('cpu')\n",
    "tune_net = build_cifar10noise(device)\n",
    "checkpoint = torch.load('checkpoints/ckpt.pth', map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 0.3279, lr 0.00100000\n",
      "Got 1748 / 2000 correct (87.40)\n",
      "\n",
      "Epoch 1, loss = 0.0554, lr 0.00100000\n",
      "Got 1755 / 2000 correct (87.75)\n",
      "\n",
      "Epoch 2, loss = 0.0853, lr 0.00100000\n",
      "Got 1833 / 2000 correct (91.65)\n",
      "\n",
      "Epoch 3, loss = 0.0352, lr 0.00100000\n",
      "Got 1829 / 2000 correct (91.45)\n",
      "\n",
      "Epoch 4, loss = 0.0192, lr 0.00100000\n",
      "Got 1851 / 2000 correct (92.55)\n",
      "\n",
      "Epoch 5, loss = 0.1141, lr 0.00100000\n",
      "Got 1853 / 2000 correct (92.65)\n",
      "\n",
      "Epoch 6, loss = 0.0827, lr 0.00100000\n",
      "Got 1809 / 2000 correct (90.45)\n",
      "\n",
      "Epoch 7, loss = 0.0281, lr 0.00100000\n",
      "Got 1769 / 2000 correct (88.45)\n",
      "\n",
      "Epoch 8, loss = 0.0231, lr 0.00100000\n",
      "Got 1725 / 2000 correct (86.25)\n",
      "\n",
      "Epoch 9, loss = 0.3755, lr 0.00100000\n",
      "Got 1734 / 2000 correct (86.70)\n",
      "\n",
      "Epoch 10, loss = 0.0638, lr 0.00100000\n",
      "Got 1772 / 2000 correct (88.60)\n",
      "\n",
      "Epoch 11, loss = 0.0381, lr 0.00100000\n",
      "Got 1775 / 2000 correct (88.75)\n",
      "\n",
      "Epoch 12, loss = 0.0132, lr 0.00100000\n",
      "Got 1783 / 2000 correct (89.15)\n",
      "\n",
      "Epoch 13, loss = 0.0046, lr 0.00100000\n",
      "Got 1812 / 2000 correct (90.60)\n",
      "\n",
      "Epoch 14, loss = 0.0011, lr 0.00100000\n",
      "Got 1817 / 2000 correct (90.85)\n",
      "\n",
      "##########\n",
      "##########\n",
      "Validation Accuracy:  0.9085\n",
      "Got 8649 / 10000 correct (86.49)\n",
      "Test Accuracy:  0.8649\n",
      "\n",
      "Epoch 0, loss = 0.2442, lr 0.00100000\n",
      "Got 1929 / 2000 correct (96.45)\n",
      "\n",
      "Epoch 1, loss = 0.0281, lr 0.00100000\n",
      "Got 1936 / 2000 correct (96.80)\n",
      "\n",
      "Epoch 2, loss = 0.0713, lr 0.00100000\n",
      "Got 1942 / 2000 correct (97.10)\n",
      "\n",
      "Epoch 3, loss = 0.0561, lr 0.00100000\n",
      "Got 1941 / 2000 correct (97.05)\n",
      "\n",
      "Epoch 4, loss = 0.0472, lr 0.00100000\n",
      "Got 1939 / 2000 correct (96.95)\n",
      "\n",
      "Epoch 5, loss = 0.0130, lr 0.00100000\n",
      "Got 1943 / 2000 correct (97.15)\n",
      "\n",
      "Epoch 6, loss = 0.0148, lr 0.00100000\n",
      "Got 1944 / 2000 correct (97.20)\n",
      "\n",
      "Epoch 7, loss = 0.0178, lr 0.00100000\n",
      "Got 1946 / 2000 correct (97.30)\n",
      "\n",
      "Epoch 8, loss = 0.0143, lr 0.00100000\n",
      "Got 1948 / 2000 correct (97.40)\n",
      "\n",
      "Epoch 9, loss = 0.0184, lr 0.00100000\n",
      "Got 1944 / 2000 correct (97.20)\n",
      "\n",
      "Epoch 10, loss = 0.0331, lr 0.00100000\n",
      "Got 1942 / 2000 correct (97.10)\n",
      "\n",
      "Epoch 11, loss = 0.0145, lr 0.00100000\n",
      "Got 1936 / 2000 correct (96.80)\n",
      "\n",
      "Epoch 12, loss = 0.0136, lr 0.00100000\n",
      "Got 1943 / 2000 correct (97.15)\n",
      "\n",
      "Epoch 13, loss = 0.0099, lr 0.00100000\n",
      "Got 1947 / 2000 correct (97.35)\n",
      "\n",
      "Epoch 14, loss = 0.0066, lr 0.00100000\n",
      "Got 1942 / 2000 correct (97.10)\n",
      "\n",
      "##########\n",
      "##########\n",
      "Validation Accuracy:  0.971\n",
      "Got 8951 / 10000 correct (89.51)\n",
      "Test Accuracy:  0.8951\n",
      "\n",
      "Epoch 0, loss = 0.1710, lr 0.00100000\n",
      "Got 1884 / 2000 correct (94.20)\n",
      "\n",
      "Epoch 1, loss = 0.0951, lr 0.00100000\n",
      "Got 1889 / 2000 correct (94.45)\n",
      "\n",
      "Epoch 2, loss = 0.0557, lr 0.00100000\n",
      "Got 1911 / 2000 correct (95.55)\n",
      "\n",
      "Epoch 3, loss = 0.0090, lr 0.00100000\n",
      "Got 1922 / 2000 correct (96.10)\n",
      "\n",
      "Epoch 4, loss = 0.0183, lr 0.00100000\n",
      "Got 1914 / 2000 correct (95.70)\n",
      "\n",
      "Epoch 5, loss = 0.0177, lr 0.00100000\n",
      "Got 1917 / 2000 correct (95.85)\n",
      "\n",
      "Epoch 6, loss = 0.0162, lr 0.00100000\n",
      "Got 1917 / 2000 correct (95.85)\n",
      "\n",
      "Epoch 7, loss = 0.0125, lr 0.00100000\n",
      "Got 1908 / 2000 correct (95.40)\n",
      "\n",
      "Epoch 8, loss = 0.0059, lr 0.00100000\n",
      "Got 1911 / 2000 correct (95.55)\n",
      "\n",
      "Epoch 9, loss = 0.0163, lr 0.00100000\n",
      "Got 1915 / 2000 correct (95.75)\n",
      "\n",
      "Epoch 10, loss = 0.0073, lr 0.00100000\n",
      "Got 1921 / 2000 correct (96.05)\n",
      "\n",
      "Epoch 11, loss = 0.0046, lr 0.00100000\n",
      "Got 1922 / 2000 correct (96.10)\n",
      "\n",
      "Epoch 12, loss = 0.0033, lr 0.00100000\n",
      "Got 1919 / 2000 correct (95.95)\n",
      "\n",
      "Epoch 13, loss = 0.0052, lr 0.00100000\n",
      "Got 1914 / 2000 correct (95.70)\n",
      "\n",
      "Epoch 14, loss = 0.0037, lr 0.00100000\n",
      "Got 1927 / 2000 correct (96.35)\n",
      "\n",
      "##########\n",
      "##########\n",
      "Validation Accuracy:  0.9635\n",
      "Got 8869 / 10000 correct (88.69)\n",
      "Test Accuracy:  0.8869\n",
      "\n",
      "Epoch 0, loss = 0.2092, lr 0.00100000\n",
      "Got 1806 / 2000 correct (90.30)\n",
      "\n",
      "Epoch 1, loss = 0.0435, lr 0.00100000\n",
      "Got 1826 / 2000 correct (91.30)\n",
      "\n",
      "Epoch 2, loss = 0.0816, lr 0.00100000\n",
      "Got 1838 / 2000 correct (91.90)\n",
      "\n",
      "Epoch 3, loss = 0.0046, lr 0.00100000\n",
      "Got 1864 / 2000 correct (93.20)\n",
      "\n",
      "Epoch 4, loss = 0.0070, lr 0.00100000\n",
      "Got 1863 / 2000 correct (93.15)\n",
      "\n",
      "Epoch 5, loss = 0.0379, lr 0.00100000\n",
      "Got 1844 / 2000 correct (92.20)\n",
      "\n",
      "Epoch 6, loss = 0.0022, lr 0.00100000\n",
      "Got 1859 / 2000 correct (92.95)\n",
      "\n",
      "Epoch 7, loss = 0.0072, lr 0.00100000\n",
      "Got 1860 / 2000 correct (93.00)\n",
      "\n",
      "Epoch 8, loss = 0.0021, lr 0.00100000\n",
      "Got 1866 / 2000 correct (93.30)\n",
      "\n",
      "Epoch 9, loss = 0.0020, lr 0.00100000\n",
      "Got 1853 / 2000 correct (92.65)\n",
      "\n",
      "Epoch 10, loss = 0.0011, lr 0.00100000\n",
      "Got 1871 / 2000 correct (93.55)\n",
      "\n",
      "Epoch 11, loss = 0.0013, lr 0.00100000\n",
      "Got 1870 / 2000 correct (93.50)\n",
      "\n",
      "Epoch 12, loss = 0.0011, lr 0.00100000\n",
      "Got 1857 / 2000 correct (92.85)\n",
      "\n",
      "Epoch 13, loss = 0.0008, lr 0.00100000\n",
      "Got 1863 / 2000 correct (93.15)\n",
      "\n",
      "Epoch 14, loss = 0.0009, lr 0.00100000\n",
      "Got 1859 / 2000 correct (92.95)\n",
      "\n",
      "##########\n",
      "##########\n",
      "Validation Accuracy:  0.9295\n",
      "Got 8758 / 10000 correct (87.58)\n",
      "Test Accuracy:  0.8758\n",
      "\n",
      "Epoch 0, loss = 0.1746, lr 0.00100000\n",
      "Got 1864 / 2000 correct (93.20)\n",
      "\n",
      "Epoch 1, loss = 0.1897, lr 0.00100000\n",
      "Got 1856 / 2000 correct (92.80)\n",
      "\n",
      "Epoch 2, loss = 0.1365, lr 0.00100000\n",
      "Got 1867 / 2000 correct (93.35)\n",
      "\n",
      "Epoch 3, loss = 0.1391, lr 0.00100000\n",
      "Got 1874 / 2000 correct (93.70)\n",
      "\n",
      "Epoch 4, loss = 0.2305, lr 0.00100000\n",
      "Got 1862 / 2000 correct (93.10)\n",
      "\n",
      "Epoch 5, loss = 0.3631, lr 0.00100000\n",
      "Got 1868 / 2000 correct (93.40)\n",
      "\n",
      "Epoch 6, loss = 0.0990, lr 0.00100000\n",
      "Got 1872 / 2000 correct (93.60)\n",
      "\n",
      "Epoch 7, loss = 0.1595, lr 0.00100000\n",
      "Got 1863 / 2000 correct (93.15)\n",
      "\n",
      "Epoch 8, loss = 0.1469, lr 0.00100000\n",
      "Got 1872 / 2000 correct (93.60)\n",
      "\n",
      "Epoch 9, loss = 0.0970, lr 0.00100000\n",
      "Got 1876 / 2000 correct (93.80)\n",
      "\n",
      "Epoch 10, loss = 0.2716, lr 0.00100000\n",
      "Got 1873 / 2000 correct (93.65)\n",
      "\n",
      "Epoch 11, loss = 0.3136, lr 0.00100000\n",
      "Got 1869 / 2000 correct (93.45)\n",
      "\n",
      "Epoch 12, loss = 0.2868, lr 0.00100000\n",
      "Got 1876 / 2000 correct (93.80)\n",
      "\n",
      "Epoch 13, loss = 0.2681, lr 0.00100000\n",
      "Got 1871 / 2000 correct (93.55)\n",
      "\n",
      "Epoch 14, loss = 0.1790, lr 0.00100000\n",
      "Got 1874 / 2000 correct (93.70)\n",
      "\n",
      "##########\n",
      "##########\n",
      "Validation Accuracy:  0.937\n",
      "Got 8654 / 10000 correct (86.54)\n",
      "Test Accuracy:  0.8654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    tune_net.load_state_dict(checkpoint['net'])\n",
    "    \n",
    "    optims = [optim.Adam(tune_net.parameters(), lr=lr, weight_decay=0.0001), optim.Adam(tune_net.layer1.parameters(), lr=lr, weight_decay=0.0001), optim.Adam(tune_net.layer2.parameters(), lr=lr, weight_decay=0.0001),\n",
    "    optim.Adam(tune_net.layer3.parameters(), lr=lr, weight_decay=0.0001), optim.Adam(tune_net.fc.parameters(), lr=lr, weight_decay=0.0001)]\n",
    "    optimizer = optims[i]\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    acc = train_cifar(tune_net, loader_val, loader_val_val, optimizer, scheduler, device=device, epochs=15)\n",
    "\n",
    "    print(\"##########\")\n",
    "    print(\"##########\")\n",
    "    print(\"Validation Accuracy: \", acc)\n",
    "    test_acc = evaluate_cifar(loader_test, tune_net, device)\n",
    "    print(\"Test Accuracy: \", test_acc)\n",
    "    print()\n",
    "    # adding results to dataframe\n",
    "    df = pd.DataFrame(columns=['val_accuracy', \"lr\", \"state\", \"noise\", \"test_accuracy\"]) \n",
    "    dict = {}\n",
    "    dict['val_accuracy'] = acc\n",
    "    dict['test_accuracy'] = test_acc\n",
    "    dict['lr'] = lr\n",
    "    dict['state'] = \"all\"\n",
    "    dict['noise'] = \"layer1\"\n",
    "    df_temp = pd.DataFrame(dict, index=[0])\n",
    "    df = pd.concat([df, df_temp])\n",
    "    names = [\"all\", \"layer1\", \"layer2\", \"layer3\", \"fc\"]\n",
    "    file_name = \"trialcifar10noise_\" + dict['noise'] + \"_\" +  names[i] + \".csv\"\n",
    "\n",
    "    df.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('torchgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20c04382e3d57c6e97c8ea72c40c86b300bd57dfe64b24ac1b7b96816a42f5b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
